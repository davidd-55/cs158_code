package ml;

import ml.classifiers.AveragePerceptronClassifier;
import ml.classifiers.Classifier;
import ml.classifiers.KNNClassifier;
import ml.data.*;

import java.util.ArrayList;
import java.util.List;

/**
 * A class to run experiments for perceptron classifiers
 *
 * Prepared for CS158 Assignment 03. Authored by David D'Attile
 */
public class A04Experimenter {

    /**
     * Main method for running the experiments specified for Assignment 2.
     * Leverages the Random and DecisionTreeClassifier classifiers for experiments.
     * @param args
     */
    public static void main(String[] args) {

        // init binary and real-valued datasets
        DataSet titanicB = getData("/Users/daviddattile/Dev/cs158_code/data/titanic-train.csv");
        DataSet titanicR = getData("/Users/daviddattile/Dev/cs158_code/data/titanic-train.real.csv");

        // init 10-fold cross validations
        CrossValidationSet cvSetBinary = new CrossValidationSet(titanicB, 10);
        CrossValidationSet cvSetReal = new CrossValidationSet(titanicR, 10);

        // init feature processors & lists
        ExampleNormalizer exampleNormalizer = new ExampleNormalizer();
        FeatureNormalizer featureNormalizer = new FeatureNormalizer();
        ArrayList<DataPreprocessor> exOnly = new ArrayList<>(){{add(exampleNormalizer);}};
        ArrayList<DataPreprocessor> featOnly = new ArrayList<>(){{add(featureNormalizer);}};
        ArrayList<DataPreprocessor> both = new ArrayList<>(){{add(exampleNormalizer);add(featureNormalizer);}};

        // init classifiers
        AveragePerceptronClassifier apClassifier = new AveragePerceptronClassifier();
        KNNClassifier knnClassifier = new KNNClassifier();

        // 1. Avg. Perceptron performance on 10-fold cross validation; titanic binary; max iterations set at 10
        double accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetBinary.getValidationSet(foldIndex, true);
            String expDesc = String.format("1-%d. Final stats from AP classifier (titanicB, max iters 10, no preprocessor over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, apClassifier, new ArrayList<>(), foldSet);
        }

        System.out.printf("1-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 2. Avg. Perceptron performance on 10-fold cross validation; titanic real valued; max iterations set at 10
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("2-%d. Final stats from AP classifier (titanicR, max iters 10, no preprocessor over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, apClassifier, new ArrayList<>(), foldSet);
        }

        System.out.printf("2-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 3a. KNN performance on 10-fold cross validation; titanic binary; K set at 3
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetBinary.getValidationSet(foldIndex, true);
            String expDesc = String.format("3a-%d. Final stats from KNN classifier (titanicB, max iters 10, no preprocessor over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, knnClassifier, new ArrayList<>(), foldSet);
        }

        System.out.printf("3a-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 3b. KNN performance on 10-fold cross validation; titanic real valued; K set at 3
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("3b-%d. Final stats from KNN classifier (titanicR, max iters 10, no preprocessor over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, knnClassifier, new ArrayList<>(), foldSet);
        }

        System.out.printf("3b-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 4a. Avg. Perceptron performance on 10-fold cross validation; ex. normalization; titanic real valued; max iters set at 10
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("4a-%d. Final stats from AP classifier (titanicR, max iters 10, ex. normalization over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, apClassifier, exOnly, foldSet);
        }

        System.out.printf("4a-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 4b. Avg. Perceptron performance on 10-fold cross validation; feature normalization; titanic real valued; max iters set at 10
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("4b-%d. Final stats from AP classifier (titanicR, max iters 10, feature normalization over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, apClassifier, featOnly, foldSet);
        }

        System.out.printf("4b-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 4c. Avg. Perceptron performance on 10-fold cross validation; both normalizations; titanic real valued; max iters set at 10
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("4c-%d. Final stats from AP classifier (titanicR, max iters 10, both normalizations over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, apClassifier, both, foldSet);
        }

        System.out.printf("4c-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 4d. KNN performance on 10-fold cross validation; ex. normalization; titanic real valued; K set at 3
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("4d-%d. Final stats from KNN classifier (titanicR, K set at 3, ex. normalization over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, knnClassifier, exOnly, foldSet);
        }

        System.out.printf("4d-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 4e. KNN performance on 10-fold cross validation; feature normalization; titanic real valued; K set at 3
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("4e-%d. Final stats from KNN classifier (titanicR, K set at 3, feature normalization over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, knnClassifier, featOnly, foldSet);
        }

        System.out.printf("4e-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);

        // 4f. KNN performance on 10-fold cross validation; both normalizations; titanic real valued; K set at 3
        accuracy = 0.0;

        for (int foldIndex = 0; foldIndex < 10; foldIndex++) {
            DataSetSplit foldSet = cvSetReal.getValidationSet(foldIndex, true);
            String expDesc = String.format("4f-%d. Final stats from KNN classifier (titanicR, K set at 3, both normalizations over 100 iters.):", foldIndex);
            accuracy += trainTestClassifier(expDesc, knnClassifier, both, foldSet);
        }

        System.out.printf("4f-10 Final average accuracy: %f%%\n\n", accuracy / 10.0);
    }

    /**
     * Trains, tests, and prints out evaluation statistics for a given classifier trained on the
     * specified data set. Data preprocessors can optionally be provided.
     *
     * @param expDescription
     * @param classifier
     * @param dataSetSplit
     * @return a double representing the accuracy of the test
     */
    public static double trainTestClassifier(
            String expDescription,
            Classifier classifier,
            List<DataPreprocessor> preprocessors,
            DataSetSplit dataSetSplit) {
        // init accuracy stats
        int correctGuesses = 0;
        int totalGuesses = 0;

        // evaluate trained classifier
        for (int i = 1; i <= 100; i++) {
            // split data
            DataSet trainData = dataSetSplit.getTrain();
            DataSet testData = dataSetSplit.getTest();

            // normalize data with specified preprocessors
            for (DataPreprocessor preprocessor : preprocessors) {
                preprocessor.preprocessTrain(trainData);
                preprocessor.preprocessTest(testData);
            }

            // train classifier
            classifier.train(trainData);

            for (Example ex : testData.getData()) {
                // classify
                double classification = classifier.classify(ex);

                // if correct, add to correct guesses
                if (classification == ex.getLabel()){
                    correctGuesses++;
                }

                // increment total guesses
                totalGuesses++;
            }
        }

        // print final stats
        System.out.println(expDescription);
        printStats(correctGuesses, totalGuesses);

        // return final test accuracy
        return (double)correctGuesses / (double)totalGuesses;
    }

    /**
     * Helper for parsing a data set.
     *
     * @return
     */
    public static DataSet getData(String fpath){
        return new DataSet(fpath);
    }

    /**
     * Helper for printing model evaluation stats.
     *
     * @param correctGuesses
     * @param totalGuesses
     */
    public static void printStats(int correctGuesses, int totalGuesses) {
        System.out.printf("-- Correct guesses: %d\n", correctGuesses);
        System.out.printf("-- Total guesses: %d\n", totalGuesses);
        System.out.printf("-- Accuracy: %f%%\n", (double)correctGuesses / (double)totalGuesses);
        System.out.println("");
    }

    /**
     * Helper for printing model evaluation stats (training and testing data).
     *
     * @param correctTrainGuesses
     * @param totalTrainGuesses
     * @param correctTestGuesses
     * @param totalTestGuesses
     */
    public static void printStatsWithTrainTestAccuracy(
            int correctTrainGuesses,
            int totalTrainGuesses,
            int correctTestGuesses,
            int totalTestGuesses) {
        System.out.printf("-- Correct training data guesses: %d\n", correctTrainGuesses);
        System.out.printf("-- Total training data guesses: %d\n", totalTrainGuesses);
        System.out.printf("-- Training data accuracy: %f%%\n", (double)correctTrainGuesses / (double)totalTrainGuesses);
        System.out.printf("-- Correct testing data guesses: %d\n", correctTestGuesses);
        System.out.printf("-- Total testing data guesses: %d\n", totalTestGuesses);
        System.out.printf("-- Testing data accuracy: %f%%\n", (double)correctTestGuesses / (double)totalTestGuesses);
        System.out.println("");
    }
}
