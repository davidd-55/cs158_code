Q1. Example network node and weight values:
Hidden node vals:
[ h1, h2, bias ]
[ -0.949826, -0.852437, 1.000000 ]

Output node val:
0.997571809785583

Hidden weights:
[ x1, x2, bias ]
[ -0.699739, 1.600104, -1.799479 ]
[ 0.030397, 0.600159, -1.399205 ]

Output weights:
[ v1, v2, bias ]
[ -1.095398, -0.595870, 1.795155 ]

Q2. Visualize testing/training accuracy and loss during network training:
iteration,sumSquaredError,trainAccuracy,TestAccuracy
1,648.000000,0.769470,0.805556
2,644.000000,0.771028,0.805556
3,644.000000,0.769470,0.819444
4,712.000000,0.750779,0.750000
5,628.000000,0.777259,0.805556
6,744.000000,0.728972,0.833333
7,620.000000,0.780374,0.805556
8,704.000000,0.753894,0.750000
9,712.000000,0.750779,0.750000
10,672.000000,0.757009,0.833333
11,624.000000,0.778816,0.805556
12,632.000000,0.775701,0.805556
13,624.000000,0.778816,0.805556
14,624.000000,0.778816,0.805556
15,652.000000,0.764798,0.833333
16,640.000000,0.771028,0.819444
17,716.000000,0.752336,0.722222
18,640.000000,0.771028,0.819444
19,652.000000,0.771028,0.777778
20,652.000000,0.771028,0.777778
21,692.000000,0.758567,0.750000
22,716.000000,0.746106,0.777778
23,612.000000,0.783489,0.805556
24,612.000000,0.783489,0.805556
25,704.000000,0.753894,0.750000
26,600.000000,0.788162,0.805556
27,632.000000,0.774143,0.819444
28,624.000000,0.777259,0.819444
29,640.000000,0.769470,0.833333
30,616.000000,0.780374,0.819444
31,612.000000,0.783489,0.805556
32,656.000000,0.769470,0.777778
33,656.000000,0.769470,0.777778
34,704.000000,0.750779,0.777778
35,664.000000,0.766355,0.777778
36,656.000000,0.769470,0.777778
37,688.000000,0.750779,0.833333
38,616.000000,0.783489,0.791667
39,600.000000,0.788162,0.805556
40,632.000000,0.774143,0.819444
41,632.000000,0.778816,0.777778
42,784.000000,0.722741,0.750000
43,692.000000,0.755452,0.777778
44,616.000000,0.781931,0.805556
45,600.000000,0.788162,0.805556
46,676.000000,0.764798,0.750000
47,796.000000,0.716511,0.763889
48,624.000000,0.778816,0.805556
49,600.000000,0.788162,0.805556
50,612.000000,0.783489,0.805556
51,600.000000,0.788162,0.805556
52,616.000000,0.783489,0.791667
53,600.000000,0.788162,0.805556
54,656.000000,0.769470,0.777778
55,604.000000,0.785047,0.819444
56,632.000000,0.778816,0.777778
57,600.000000,0.788162,0.805556
58,600.000000,0.788162,0.805556
59,632.000000,0.778816,0.777778
60,684.000000,0.760125,0.763889
61,608.000000,0.785047,0.805556
62,604.000000,0.785047,0.819444
63,604.000000,0.786604,0.805556
64,664.000000,0.771028,0.736111
65,600.000000,0.788162,0.805556
66,596.000000,0.789720,0.805556
67,688.000000,0.760125,0.750000
68,632.000000,0.778816,0.777778
69,620.000000,0.778816,0.819444
70,628.000000,0.777259,0.805556
71,620.000000,0.777259,0.833333
72,656.000000,0.769470,0.777778
73,640.000000,0.769470,0.833333
74,632.000000,0.778816,0.777778
75,632.000000,0.774143,0.819444
76,612.000000,0.783489,0.805556
77,600.000000,0.788162,0.805556
78,616.000000,0.781931,0.805556
79,684.000000,0.752336,0.833333
80,604.000000,0.785047,0.819444
81,660.000000,0.771028,0.750000
82,632.000000,0.778816,0.777778
83,600.000000,0.789720,0.791667
84,596.000000,0.789720,0.805556
85,600.000000,0.788162,0.805556
86,632.000000,0.778816,0.777778
87,608.000000,0.785047,0.805556
88,640.000000,0.775701,0.777778
89,732.000000,0.742991,0.750000
90,620.000000,0.780374,0.805556
91,620.000000,0.778816,0.819444
92,612.000000,0.781931,0.819444
93,624.000000,0.777259,0.819444
94,604.000000,0.785047,0.819444
95,684.000000,0.766355,0.708333
96,600.000000,0.788162,0.805556
97,632.000000,0.778816,0.777778
98,600.000000,0.788162,0.805556
99,632.000000,0.778816,0.777778
100,600.000000,0.788162,0.805556
101,792.000000,0.719626,0.750000
102,600.000000,0.788162,0.805556
103,632.000000,0.778816,0.777778
104,632.000000,0.778816,0.777778
105,608.000000,0.786604,0.791667
106,600.000000,0.788162,0.805556
107,608.000000,0.786604,0.791667
108,632.000000,0.778816,0.777778
109,676.000000,0.757009,0.819444
110,632.000000,0.778816,0.777778
111,608.000000,0.786604,0.791667
112,596.000000,0.789720,0.805556
113,620.000000,0.780374,0.805556
114,624.000000,0.778816,0.805556
115,660.000000,0.771028,0.750000
116,684.000000,0.760125,0.763889
117,596.000000,0.789720,0.805556
118,684.000000,0.761682,0.750000
119,864.000000,0.683801,0.819444
120,676.000000,0.755452,0.833333
121,604.000000,0.785047,0.819444
122,632.000000,0.778816,0.777778
123,612.000000,0.783489,0.805556
124,632.000000,0.778816,0.777778
125,596.000000,0.789720,0.805556
126,628.000000,0.777259,0.805556
127,596.000000,0.789720,0.805556
128,720.000000,0.752336,0.708333
129,612.000000,0.783489,0.805556
130,692.000000,0.749221,0.833333
131,836.000000,0.694704,0.819444
132,600.000000,0.788162,0.805556
133,628.000000,0.775701,0.819444
134,668.000000,0.769470,0.736111
135,664.000000,0.769470,0.750000
136,632.000000,0.778816,0.777778
137,600.000000,0.788162,0.805556
138,684.000000,0.752336,0.833333
139,632.000000,0.778816,0.777778
140,596.000000,0.789720,0.805556
141,692.000000,0.750779,0.819444
142,632.000000,0.778816,0.777778
143,620.000000,0.778816,0.819444
144,604.000000,0.785047,0.819444
145,604.000000,0.788162,0.791667
146,676.000000,0.764798,0.750000
147,632.000000,0.778816,0.777778
148,608.000000,0.785047,0.805556
149,684.000000,0.761682,0.750000
150,632.000000,0.778816,0.777778
151,596.000000,0.789720,0.805556
152,624.000000,0.778816,0.805556
153,600.000000,0.788162,0.805556
154,600.000000,0.788162,0.805556
155,600.000000,0.788162,0.805556
156,632.000000,0.778816,0.777778
157,828.000000,0.699377,0.805556
158,612.000000,0.781931,0.819444
159,904.000000,0.677570,0.736111
160,620.000000,0.778816,0.819444
161,792.000000,0.722741,0.722222
162,632.000000,0.778816,0.777778
163,612.000000,0.783489,0.805556
164,632.000000,0.778816,0.777778
165,824.000000,0.700935,0.805556
166,636.000000,0.771028,0.833333
167,608.000000,0.786604,0.791667
168,628.000000,0.777259,0.805556
169,632.000000,0.778816,0.777778
170,604.000000,0.788162,0.791667
171,612.000000,0.783489,0.805556
172,640.000000,0.777259,0.763889
173,628.000000,0.780374,0.777778
174,604.000000,0.786604,0.805556
175,612.000000,0.785047,0.791667
176,600.000000,0.788162,0.805556
177,620.000000,0.778816,0.819444
178,604.000000,0.785047,0.819444
179,688.000000,0.758567,0.763889
180,600.000000,0.788162,0.805556
181,668.000000,0.767913,0.750000
182,600.000000,0.788162,0.805556
183,600.000000,0.788162,0.805556
184,636.000000,0.771028,0.833333
185,608.000000,0.783489,0.819444
186,612.000000,0.781931,0.819444
187,600.000000,0.788162,0.805556
188,632.000000,0.778816,0.777778
189,632.000000,0.778816,0.777778
190,600.000000,0.788162,0.805556
191,632.000000,0.778816,0.777778
192,604.000000,0.786604,0.805556
193,604.000000,0.788162,0.791667
194,604.000000,0.786604,0.805556
195,632.000000,0.778816,0.777778
196,600.000000,0.788162,0.805556
197,632.000000,0.778816,0.777778
198,840.000000,0.693146,0.819444
199,600.000000,0.788162,0.805556
200,628.000000,0.774143,0.833333

Q3. Impact of number of hidden nodes on network accuracy:
Node count: 1
fold,trainAccuracy,testAccuracy
0,0.776050,0.549296
1,0.772939,0.802817
2,0.808709,0.521127
3,0.769829,0.845070
4,0.769829,0.845070
5,0.780715,0.760563
6,0.777605,0.802817
7,0.776050,0.802817
8,0.785381,0.732394
9,0.760563,0.666667
avg,0.777767,0.732864

Node count: 2
fold,trainAccuracy,testAccuracy
0,0.780715,0.549296
1,0.743390,0.704225
2,0.811820,0.507042
3,0.782271,0.859155
4,0.785381,0.830986
5,0.793157,0.760563
6,0.744946,0.774648
7,0.786936,0.802817
8,0.741835,0.647887
9,0.776213,0.866667
avg,0.774666,0.730329

Node count: 3
fold,trainAccuracy,testAccuracy
0,0.769829,0.563380
1,0.772939,0.746479
2,0.813375,0.507042
3,0.782271,0.746479
4,0.774495,0.816901
5,0.788491,0.732394
6,0.776050,0.802817
7,0.782271,0.732394
8,0.794712,0.732394
9,0.774648,0.666667
avg,0.782908,0.704695

Node count: 4
fold,trainAccuracy,testAccuracy
0,0.749611,0.436620
1,0.772939,0.774648
2,0.811820,0.521127
3,0.771384,0.830986
4,0.776050,0.845070
5,0.797823,0.704225
6,0.783826,0.746479
7,0.783826,0.845070
8,0.779160,0.732394
9,0.769953,0.853333
avg,0.779639,0.728995

Node count: 5
fold,trainAccuracy,testAccuracy
0,0.777605,0.788732
1,0.766719,0.802817
2,0.807154,0.507042
3,0.780715,0.859155
4,0.774495,0.816901
5,0.794712,0.718310
6,0.738725,0.704225
7,0.769829,0.845070
8,0.796267,0.732394
9,0.771518,0.653333
avg,0.777774,0.742798

Node count: 6
fold,trainAccuracy,testAccuracy
0,0.751166,0.549296
1,0.760498,0.760563
2,0.807154,0.535211
3,0.695179,0.732394
4,0.765163,0.845070
5,0.769829,0.746479
6,0.709176,0.690141
7,0.771384,0.845070
8,0.782271,0.718310
9,0.780908,0.866667
avg,0.759273,0.728920

Node count: 7
fold,trainAccuracy,testAccuracy
0,0.780715,0.718310
1,0.785381,0.802817
2,0.804044,0.535211
3,0.782271,0.859155
4,0.785381,0.830986
5,0.797823,0.704225
6,0.779160,0.760563
7,0.785381,0.845070
8,0.793157,0.732394
9,0.780908,0.866667
avg,0.787422,0.765540

Node count: 8
fold,trainAccuracy,testAccuracy
0,0.755832,0.704225
1,0.737170,0.802817
2,0.811820,0.507042
3,0.758942,0.746479
4,0.774495,0.816901
5,0.793157,0.760563
6,0.758942,0.732394
7,0.766719,0.760563
8,0.786936,0.746479
9,0.737089,0.813333
avg,0.768110,0.739080

Node count: 9
fold,trainAccuracy,testAccuracy
0,0.720062,0.507042
1,0.760498,0.802817
2,0.810264,0.507042
3,0.780715,0.746479
4,0.785381,0.845070
5,0.780715,0.760563
6,0.765163,0.802817
7,0.716952,0.633803
8,0.796267,0.732394
9,0.780908,0.866667
avg,0.769693,0.720469

Node count: 10
fold,trainAccuracy,testAccuracy
0,0.757387,0.619718
1,0.785381,0.746479
2,0.804044,0.535211
3,0.743390,0.746479
4,0.785381,0.830986
5,0.794712,0.760563
6,0.788491,0.802817
7,0.771384,0.845070
8,0.777605,0.676056
9,0.769953,0.866667
avg,0.777773,0.743005

Q4. Find the ideal NN:
eta,avgTrainAccuracy,avgTestAccuracy
0.000000,0.520115,0.537089
0.010000,0.788823,0.727230
0.020000,0.787576,0.728563
0.030000,0.787419,0.758723
0.040000,0.779805,0.746047
0.050000,0.789909,0.725897
0.060000,0.783378,0.741746
0.070000,0.778084,0.738779
0.080000,0.781352,0.751831
0.090000,0.775135,0.771174
0.100000,0.780579,0.737014
0.110000,0.782904,0.757089
0.120000,0.783378,0.738779
0.130000,0.768758,0.759399
0.140000,0.763467,0.720188
0.150000,0.779958,0.738779
0.160000,0.781038,0.739906
0.170000,0.774039,0.713146
0.180000,0.755363,0.704695
0.190000,0.762597,0.702197
0.200000,0.780228,0.749014
0.210000,0.773725,0.733972
0.220000,0.782914,0.748864
0.230000,0.776358,0.743080
0.240000,0.779947,0.731155
0.250000,0.786800,0.750122
0.260000,0.783691,0.758498
0.270000,0.781024,0.764657
0.280000,0.787733,0.757089
0.290000,0.777770,0.739681
0.300000,0.776686,0.751099
0.310000,0.785708,0.733146
0.320000,0.785548,0.765540
0.330000,0.780424,0.735962
0.340000,0.778239,0.769765
0.350000,0.757407,0.727512
0.360000,0.773095,0.750347
0.370000,0.774513,0.754272
0.380000,0.782135,0.760207
0.390000,0.782753,0.775399
0.400000,0.778239,0.771174
0.410000,0.761913,0.766948
0.420000,0.770309,0.769765
0.430000,0.746202,0.720469
0.440000,0.761448,0.744413
0.450000,0.771380,0.761033
0.460000,0.727702,0.699343
0.470000,0.729250,0.728920
0.480000,0.701502,0.691080
0.490000,0.727691,0.656808

iterations,avgTrainAccuracy,avgTestAccuracy
1,0.774657,0.747531
2,0.759552,0.753089
3,0.741531,0.717371
4,0.761748,0.749765
5,0.764548,0.745540
6,0.765427,0.740939
7,0.773100,0.761315
8,0.776836,0.753164
9,0.759105,0.752357
10,0.765642,0.748638
11,0.736398,0.673709
12,0.765474,0.750347
13,0.673601,0.651643
14,0.772954,0.754272
15,0.769530,0.743005
16,0.774810,0.732638
17,0.765636,0.717371
18,0.771086,0.745822
19,0.766733,0.758498
20,0.776066,0.769991
21,0.762370,0.717371
22,0.772020,0.740188
23,0.770311,0.726329
24,0.771552,0.724695
25,0.770448,0.764207
26,0.767507,0.732038
27,0.766725,0.730047
28,0.774175,0.741746
29,0.775442,0.762723
30,0.762217,0.740263
31,0.760514,0.747455
32,0.777462,0.755981
33,0.769528,0.735681
34,0.775902,0.753089
35,0.786016,0.764131
36,0.769375,0.734554
37,0.771709,0.744488
38,0.761577,0.689052
39,0.774196,0.757089
40,0.772793,0.745822
41,0.771863,0.747230
42,0.758615,0.716394
43,0.774196,0.751455
44,0.764391,0.735681
45,0.769208,0.744413
46,0.774971,0.721878
47,0.763416,0.739756
48,0.773252,0.747305
49,0.762373,0.731155
50,0.776689,0.759906
51,0.777307,0.747305
52,0.770146,0.732563
53,0.758623,0.727587
54,0.766733,0.751455
55,0.775286,0.728638
56,0.773568,0.757089
57,0.757399,0.744413
58,0.781202,0.757390
59,0.775595,0.752864
60,0.776373,0.741897
61,0.772337,0.743305
62,0.771396,0.764131
63,0.777304,0.714254
64,0.774967,0.728714
65,0.767826,0.765540
66,0.776220,0.728338
67,0.766110,0.731455
68,0.782595,0.757164
69,0.769345,0.741164
70,0.782283,0.745540
71,0.776059,0.741596
72,0.777617,0.737671
73,0.750095,0.731737
74,0.768908,0.700244
75,0.772480,0.703286
76,0.775755,0.741014
77,0.774512,0.754272
78,0.751646,0.711944
79,0.763608,0.720188
80,0.770928,0.710028
81,0.780570,0.756808
82,0.770606,0.749765
83,0.783060,0.762723
84,0.765641,0.730329
85,0.779449,0.765690
86,0.777002,0.737371
87,0.774512,0.706103
88,0.775291,0.727230
89,0.775904,0.744488
90,0.763931,0.752864
91,0.774667,0.745822
92,0.782132,0.754272
93,0.779007,0.738272
94,0.760772,0.741897
95,0.769063,0.731737
96,0.775284,0.740188
97,0.779483,0.762723
98,0.774350,0.728563
99,0.778698,0.741315
100,0.774975,0.736939
101,0.754136,0.711812
102,0.743705,0.673709
103,0.775447,0.761315
104,0.777931,0.732638
105,0.767820,0.737671
106,0.769533,0.711737
107,0.778090,0.731531
108,0.770002,0.737371
109,0.779179,0.748638
110,0.768136,0.713427
111,0.777933,0.751099
112,0.773887,0.742648
113,0.776839,0.731380
114,0.784623,0.757089
115,0.786021,0.757089
116,0.771391,0.733446
117,0.785396,0.737014
118,0.772640,0.752864
119,0.774662,0.757089
120,0.770618,0.737371
121,0.775126,0.747305
122,0.773722,0.751531
123,0.770146,0.723005
124,0.774334,0.766948
125,0.772336,0.768357
126,0.775135,0.737371
127,0.779014,0.728638
128,0.767361,0.727737
129,0.780268,0.734554
130,0.771819,0.727887
131,0.770151,0.754272
132,0.778554,0.737089
133,0.773736,0.731380
134,0.776209,0.750948
135,0.771196,0.731756
136,0.784779,0.746873
137,0.772800,0.731531
138,0.776693,0.737014
139,0.776065,0.738704
140,0.775600,0.725897
141,0.781193,0.745540
142,0.778398,0.738272
143,0.768551,0.721822
144,0.782134,0.775399
145,0.776069,0.739831
146,0.777458,0.724695
147,0.772795,0.761315
148,0.785710,0.745822
149,0.774183,0.704695
150,0.770464,0.746873
151,0.779173,0.751831
152,0.765332,0.723005
153,0.762212,0.707662
154,0.772951,0.747230
155,0.783378,0.761315
156,0.772025,0.766948
157,0.780259,0.746122
158,0.779020,0.728638
159,0.769225,0.729972
160,0.768120,0.733296
161,0.778550,0.744413
162,0.763465,0.682160
163,0.774662,0.721596
164,0.772025,0.721878
165,0.771551,0.759906
166,0.771546,0.750122
167,0.764400,0.744338
168,0.776380,0.747230
169,0.767974,0.748638
170,0.772176,0.735606
171,0.772643,0.751531
172,0.780729,0.731380
173,0.779794,0.755681
174,0.775593,0.725521
175,0.784311,0.738779
176,0.777312,0.739831
177,0.766114,0.759906
178,0.779024,0.726103
179,0.776526,0.720188
180,0.772177,0.724845
181,0.773581,0.738779
182,0.778705,0.745822
183,0.776810,0.710629
184,0.778861,0.750047
185,0.779948,0.723005
186,0.779949,0.757089
187,0.770469,0.738779
188,0.770876,0.750347
189,0.768285,0.743005
190,0.773074,0.737315
191,0.777779,0.738423
192,0.765750,0.734854
193,0.777457,0.739831
194,0.775438,0.731380
195,0.767671,0.765540
196,0.781510,0.727155
197,0.765649,0.720113
198,0.781979,0.744413
199,0.768402,0.715737
200,0.782757,0.734197

fold,avgTrainAccuracy,avgTestAccuracy
0,0.779160,0.746479
1,0.788491,0.802817
2,0.808709,0.521127
3,0.740280,0.845070
4,0.772939,0.845070
5,0.785381,0.760563
6,0.768274,0.802817
7,0.727838,0.788732
8,0.785381,0.732394
9,0.779343,0.866667
avg,0.773580,0.771174

Q5. Evaluate tanh vs. sigmoid performance (7 hidden nodes):
fold,avgTanhTrainAccuracy,avgTanhTestAccuracy,avgSigmoidTrainAccuracy,avgSigmoidTestAccuracy
0,0.763608,0.704225,0.785381,0.619718
1,0.713841,0.816901,0.786936,0.774648
2,0.811820,0.507042,0.808709,0.521127
3,0.782271,0.859155,0.774495,0.859155
4,0.774495,0.816901,0.777605,0.830986
5,0.794712,0.718310,0.786936,0.760563
6,0.709176,0.690141,0.782271,0.802817
7,0.780715,0.746479,0.780715,0.802817
8,0.785381,0.718310,0.796267,0.732394
9,0.763693,0.866667,0.769953,0.720000
avg,0.767971,0.744413,0.784927,0.742423
